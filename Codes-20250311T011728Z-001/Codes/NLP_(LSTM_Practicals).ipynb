{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pgt2bbFUr2gZ"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Data plays a vital role in our everyday life.\n",
        "Directly or indirectly, for daily life decisions, we depend on some data, be it choosing a novel to read from a list of books, buying a thing after considering the budget, and so on.\n",
        "Have you ever imagined searching for something on Google or Yahoo generates a lot of data?\n",
        "This data is essential to analyze user experiences.\n",
        "Getting recommendations on various e-commerce websites after buying a product and tracking parcels during delivery are part of Data Analytics which involves analyzing the raw data to make informed decisions.\n",
        "But this raw data does not help make decisions if it has some redundancy, inconsistency, or inaccuracy.\n",
        "Therefore, this data needs to be cleaned before considering for analysis.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "hRY9s1CNwyCC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "PW-VY5avMM-k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "KKzj7JNzMSSJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8myerEMVTB",
        "outputId": "314af72f-73d6-42f9-ec27-73a31b1e073f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split('\\n'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRl6t-h0NRNw",
        "outputId": "f63fcbf0-0881-48c3-b4dc-28eaec143454"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data plays a vital role in our everyday life.\n",
            "Directly or indirectly, for daily life decisions, we depend on some data, be it choosing a novel to read from a list of books, buying a thing after considering the budget, and so on.\n",
            "Have you ever imagined searching for something on Google or Yahoo generates a lot of data?\n",
            "This data is essential to analyze user experiences.\n",
            "Getting recommendations on various e-commerce websites after buying a product and tracking parcels during delivery are part of Data Analytics which involves analyzing the raw data to make informed decisions.\n",
            "But this raw data does not help make decisions if it has some redundancy, inconsistency, or inaccuracy.\n",
            "Therefore, this data needs to be cleaned before considering for analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split('\\n'):\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkRWZeniMhH6",
        "outputId": "0af75b26-c85e-4318-c7ad-d65071e9f6ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 21, 2, 22, 23, 24, 25, 26, 10]\n",
            "[27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35, 2, 36, 8, 37, 14, 2, 38, 15, 16, 17, 39, 18, 40, 3]\n",
            "[41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8, 1]\n",
            "[9, 1, 51, 52, 4, 53, 54, 55]\n",
            "[56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8, 1, 69, 70, 71, 72, 17, 19, 1, 4, 20, 73, 7]\n",
            "[74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5, 82]\n",
            "[83, 9, 1, 84, 4, 12, 85, 86, 16, 6, 87]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for sentence in text.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "6J5y6cYCMrMB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJ1jTKgOJoB",
        "outputId": "a386615f-e769-4aa1-c9ec-ad29d6874eb4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 21],\n",
              " [1, 21, 2],\n",
              " [1, 21, 2, 22],\n",
              " [1, 21, 2, 22, 23],\n",
              " [1, 21, 2, 22, 23, 24],\n",
              " [1, 21, 2, 22, 23, 24, 25],\n",
              " [1, 21, 2, 22, 23, 24, 25, 26],\n",
              " [1, 21, 2, 22, 23, 24, 25, 26, 10],\n",
              " [27, 5],\n",
              " [27, 5, 28],\n",
              " [27, 5, 28, 6],\n",
              " [27, 5, 28, 6, 29],\n",
              " [27, 5, 28, 6, 29, 10],\n",
              " [27, 5, 28, 6, 29, 10, 7],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35, 2],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18,\n",
              "  40],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18,\n",
              "  40,\n",
              "  3],\n",
              " [41, 42],\n",
              " [41, 42, 43],\n",
              " [41, 42, 43, 44],\n",
              " [41, 42, 43, 44, 45],\n",
              " [41, 42, 43, 44, 45, 6],\n",
              " [41, 42, 43, 44, 45, 6, 46],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8, 1],\n",
              " [9, 1],\n",
              " [9, 1, 51],\n",
              " [9, 1, 51, 52],\n",
              " [9, 1, 51, 52, 4],\n",
              " [9, 1, 51, 52, 4, 53],\n",
              " [9, 1, 51, 52, 4, 53, 54],\n",
              " [9, 1, 51, 52, 4, 53, 54, 55],\n",
              " [56, 57],\n",
              " [56, 57, 3],\n",
              " [56, 57, 3, 58],\n",
              " [56, 57, 3, 58, 59],\n",
              " [56, 57, 3, 58, 59, 60],\n",
              " [56, 57, 3, 58, 59, 60, 61],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8, 1],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20,\n",
              "  73],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20,\n",
              "  73,\n",
              "  7],\n",
              " [74, 9],\n",
              " [74, 9, 19],\n",
              " [74, 9, 19, 1],\n",
              " [74, 9, 19, 1, 75],\n",
              " [74, 9, 19, 1, 75, 76],\n",
              " [74, 9, 19, 1, 75, 76, 77],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5, 82],\n",
              " [83, 9],\n",
              " [83, 9, 1],\n",
              " [83, 9, 1, 84],\n",
              " [83, 9, 1, 84, 4],\n",
              " [83, 9, 1, 84, 4, 12],\n",
              " [83, 9, 1, 84, 4, 12, 85],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16, 6],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16, 6, 87]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "8lr5MiQZOQQx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKcYzKINUCqt",
        "outputId": "3ff88025-d949-40c9-b5d1-96c7a545b4a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "vkZZGWTfTeZP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3PvqWMHT7G3",
        "outputId": "57c63a7f-9cf8-48f9-e0d6-b2b4f325c0bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  1, 21],\n",
              "       [ 0,  0,  0, ...,  1, 21,  2],\n",
              "       [ 0,  0,  0, ..., 21,  2, 22],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 85, 86, 16],\n",
              "       [ 0,  0,  0, ..., 86, 16,  6],\n",
              "       [ 0,  0,  0, ..., 16,  6, 87]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "-mXCxNOqUmoW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7EX8AUIVLpw",
        "outputId": "10ccd160-2424-4338-85e1-ecd09e13a805"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  1],\n",
              "       [ 0,  0,  0, ...,  0,  1, 21],\n",
              "       [ 0,  0,  0, ...,  1, 21,  2],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 12, 85, 86],\n",
              "       [ 0,  0,  0, ..., 85, 86, 16],\n",
              "       [ 0,  0,  0, ..., 86, 16,  6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djQ-7TTSVTkQ",
        "outputId": "7811f839-d39d-4222-bbb8-d642dea4e211"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21,  2, 22, 23, 24, 25, 26, 10,  5, 28,  6, 29, 10,  7, 30, 31,  3,\n",
              "       11,  1, 12, 13, 32,  2, 33,  4, 34, 35,  2, 36,  8, 37, 14,  2, 38,\n",
              "       15, 16, 17, 39, 18, 40,  3, 42, 43, 44, 45,  6, 46,  3, 47,  5, 48,\n",
              "       49,  2, 50,  8,  1,  1, 51, 52,  4, 53, 54, 55, 57,  3, 58, 59, 60,\n",
              "       61, 15, 14,  2, 62, 18, 63, 64, 65, 66, 67, 68,  8,  1, 69, 70, 71,\n",
              "       72, 17, 19,  1,  4, 20, 73,  7,  9, 19,  1, 75, 76, 77, 20,  7, 78,\n",
              "       13, 79, 11, 80, 81,  5, 82,  9,  1, 84,  4, 12, 85, 86, 16,  6, 87],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTseIyqMfkYd",
        "outputId": "998d2867-0eb9-4a96-f370-428267f7b8ec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': 1,\n",
              " 'a': 2,\n",
              " 'on': 3,\n",
              " 'to': 4,\n",
              " 'or': 5,\n",
              " 'for': 6,\n",
              " 'decisions': 7,\n",
              " 'of': 8,\n",
              " 'this': 9,\n",
              " 'life': 10,\n",
              " 'some': 11,\n",
              " 'be': 12,\n",
              " 'it': 13,\n",
              " 'buying': 14,\n",
              " 'after': 15,\n",
              " 'considering': 16,\n",
              " 'the': 17,\n",
              " 'and': 18,\n",
              " 'raw': 19,\n",
              " 'make': 20,\n",
              " 'plays': 21,\n",
              " 'vital': 22,\n",
              " 'role': 23,\n",
              " 'in': 24,\n",
              " 'our': 25,\n",
              " 'everyday': 26,\n",
              " 'directly': 27,\n",
              " 'indirectly': 28,\n",
              " 'daily': 29,\n",
              " 'we': 30,\n",
              " 'depend': 31,\n",
              " 'choosing': 32,\n",
              " 'novel': 33,\n",
              " 'read': 34,\n",
              " 'from': 35,\n",
              " 'list': 36,\n",
              " 'books': 37,\n",
              " 'thing': 38,\n",
              " 'budget': 39,\n",
              " 'so': 40,\n",
              " 'have': 41,\n",
              " 'you': 42,\n",
              " 'ever': 43,\n",
              " 'imagined': 44,\n",
              " 'searching': 45,\n",
              " 'something': 46,\n",
              " 'google': 47,\n",
              " 'yahoo': 48,\n",
              " 'generates': 49,\n",
              " 'lot': 50,\n",
              " 'is': 51,\n",
              " 'essential': 52,\n",
              " 'analyze': 53,\n",
              " 'user': 54,\n",
              " 'experiences': 55,\n",
              " 'getting': 56,\n",
              " 'recommendations': 57,\n",
              " 'various': 58,\n",
              " 'e': 59,\n",
              " 'commerce': 60,\n",
              " 'websites': 61,\n",
              " 'product': 62,\n",
              " 'tracking': 63,\n",
              " 'parcels': 64,\n",
              " 'during': 65,\n",
              " 'delivery': 66,\n",
              " 'are': 67,\n",
              " 'part': 68,\n",
              " 'analytics': 69,\n",
              " 'which': 70,\n",
              " 'involves': 71,\n",
              " 'analyzing': 72,\n",
              " 'informed': 73,\n",
              " 'but': 74,\n",
              " 'does': 75,\n",
              " 'not': 76,\n",
              " 'help': 77,\n",
              " 'if': 78,\n",
              " 'has': 79,\n",
              " 'redundancy': 80,\n",
              " 'inconsistency': 81,\n",
              " 'inaccuracy': 82,\n",
              " 'therefore': 83,\n",
              " 'needs': 84,\n",
              " 'cleaned': 85,\n",
              " 'before': 86,\n",
              " 'analysis': 87}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=88)"
      ],
      "metadata": {
        "id": "BikWaC4fg0y1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62RBz7AwhCe0",
        "outputId": "1907bec3-bea2-48dc-902f-d919f8771144"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vns3pQFNhSFq",
        "outputId": "e4d0ab2d-f2a1-459d-d863-1b0e1d841e24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Building**"
      ],
      "metadata": {
        "id": "hyFeZ9R1FPzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "3JGGM9PlhTqK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(88,100,input_length=33))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(88,activation='softmax'))"
      ],
      "metadata": {
        "id": "lIbSgCVHFbO_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bDG251CFFgHX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JgOuNxiGPgH",
        "outputId": "c6a38260-539f-44d1-d1c5-1e3a9dbff671"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 33, 100)           8800      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 88)                13288     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 172688 (674.56 KB)\n",
            "Trainable params: 172688 (674.56 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWHNq7UQIW6T",
        "outputId": "e9177df1-32ad-4792-9a08-eac680180b29"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agZhL4gCMRgx",
        "outputId": "cd7f6e68-2652-4e98-97ef-1579182827c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpx97gBhMS2y",
        "outputId": "7801fbe3-8931-499d-eb13-0c6f83ee6810"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 3s 58ms/step - loss: 4.4787 - accuracy: 0.0168\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 4.4591 - accuracy: 0.0588\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 4.4255 - accuracy: 0.0588\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 4.3552 - accuracy: 0.0588\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 4.3163 - accuracy: 0.0588\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 4.2763 - accuracy: 0.0588\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 4.2575 - accuracy: 0.0588\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 4.2233 - accuracy: 0.0924\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 4.1903 - accuracy: 0.1008\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 4.1400 - accuracy: 0.0756\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 4.0911 - accuracy: 0.1176\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 4.0238 - accuracy: 0.0672\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 3.9413 - accuracy: 0.1008\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 3.8746 - accuracy: 0.0756\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 3.7742 - accuracy: 0.1092\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 3.6896 - accuracy: 0.1176\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 3.5807 - accuracy: 0.1176\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 3.4669 - accuracy: 0.1261\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 3.3771 - accuracy: 0.1345\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 3.2587 - accuracy: 0.1345\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 3.1591 - accuracy: 0.1681\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 3.0495 - accuracy: 0.1933\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 2.9176 - accuracy: 0.2185\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 2.8446 - accuracy: 0.2101\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 2.7404 - accuracy: 0.2437\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 118ms/step - loss: 2.6197 - accuracy: 0.2773\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 2.5412 - accuracy: 0.3193\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 2.4392 - accuracy: 0.3529\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 107ms/step - loss: 2.3884 - accuracy: 0.3277\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 2.3172 - accuracy: 0.3866\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 2.2282 - accuracy: 0.4874\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.1600 - accuracy: 0.4286\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 2.0915 - accuracy: 0.4790\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 2.0331 - accuracy: 0.4622\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.9844 - accuracy: 0.4622\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 1.9223 - accuracy: 0.5042\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.8566 - accuracy: 0.5210\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.7929 - accuracy: 0.5882\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.7639 - accuracy: 0.5714\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.7154 - accuracy: 0.6050\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.6798 - accuracy: 0.6471\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.6394 - accuracy: 0.6303\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.6000 - accuracy: 0.6723\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.5274 - accuracy: 0.7731\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.5036 - accuracy: 0.7227\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.4680 - accuracy: 0.7227\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.4257 - accuracy: 0.7815\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.3935 - accuracy: 0.7899\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.3737 - accuracy: 0.7899\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 1.3725 - accuracy: 0.7311\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.3403 - accuracy: 0.7563\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.2880 - accuracy: 0.8403\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.2882 - accuracy: 0.8235\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.2799 - accuracy: 0.7563\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.2241 - accuracy: 0.8319\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.1954 - accuracy: 0.8403\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.1511 - accuracy: 0.9076\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 1.1326 - accuracy: 0.8487\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.1040 - accuracy: 0.8655\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 1.0677 - accuracy: 0.8908\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 1.0481 - accuracy: 0.9244\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 1.0132 - accuracy: 0.9496\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0063 - accuracy: 0.9496\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 1.0007 - accuracy: 0.8992\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9758 - accuracy: 0.9328\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9576 - accuracy: 0.9412\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9556 - accuracy: 0.9160\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.9592 - accuracy: 0.8824\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9292 - accuracy: 0.9160\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.9019 - accuracy: 0.9412\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 108ms/step - loss: 0.8878 - accuracy: 0.9328\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.8531 - accuracy: 0.9664\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.8485 - accuracy: 0.9496\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.8372 - accuracy: 0.9580\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.8024 - accuracy: 0.9832\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.7791 - accuracy: 0.9832\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.7512 - accuracy: 0.9832\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.7472 - accuracy: 0.9748\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.7324 - accuracy: 0.9832\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.7376 - accuracy: 0.9748\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.7396 - accuracy: 0.9496\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.6900 - accuracy: 0.9832\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.6784 - accuracy: 0.9832\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.6594 - accuracy: 0.9916\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.6541 - accuracy: 0.9916\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.6505 - accuracy: 0.9916\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6589 - accuracy: 0.9664\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.6359 - accuracy: 0.9664\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6347 - accuracy: 0.9832\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6162 - accuracy: 0.9832\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5971 - accuracy: 0.9916\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.5832 - accuracy: 0.9832\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5769 - accuracy: 0.9832\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5734 - accuracy: 0.9748\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.5545 - accuracy: 0.9916\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.5551 - accuracy: 0.9832\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.5578 - accuracy: 0.9664\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5641 - accuracy: 0.9748\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.5794 - accuracy: 0.9664\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5640 - accuracy: 0.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df8a7cc7910>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Test the model**"
      ],
      "metadata": {
        "id": "TQPjc7WqMqxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"Data\"\n",
        "\n",
        "# tokenization\n",
        "token_text = tokenizer.texts_to_sequences([text2])[0]\n",
        "# padding\n",
        "padded_text = pad_sequences([token_text], maxlen=33, padding='pre')\n",
        "# model prediction\n",
        "model.predict(padded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MUI7BxvMW-J",
        "outputId": "6799f6e7-9fa0-4b62-c328-ceb5f4e1b628"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 472ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.45734627e-05, 1.26025258e-02, 2.52674147e-02, 1.82166062e-02,\n",
              "        6.88905176e-03, 2.86871623e-02, 2.39147176e-03, 1.54899040e-04,\n",
              "        3.02735483e-04, 6.97048977e-02, 5.56870713e-04, 4.58810428e-05,\n",
              "        2.18526297e-03, 5.81620843e-05, 1.02203878e-04, 1.33914917e-04,\n",
              "        2.62645510e-04, 4.67326085e-04, 1.21927776e-04, 3.48947048e-02,\n",
              "        1.17657481e-04, 5.02192497e-01, 1.52991991e-02, 4.79203602e-03,\n",
              "        3.16841202e-03, 7.92651263e-04, 5.02543640e-04, 7.55686460e-06,\n",
              "        1.62513126e-02, 2.03731656e-03, 1.71809515e-04, 1.53344125e-04,\n",
              "        7.41737313e-05, 3.47796158e-05, 1.95762077e-05, 1.52567145e-05,\n",
              "        4.91693572e-05, 9.53256531e-05, 8.92256285e-05, 1.91276602e-04,\n",
              "        1.99729504e-04, 1.28044348e-05, 1.05340714e-02, 4.22906410e-03,\n",
              "        1.55440136e-03, 3.53630487e-04, 1.26286439e-04, 2.23115872e-04,\n",
              "        1.98264985e-04, 8.70143704e-05, 1.49152314e-04, 1.00956112e-01,\n",
              "        1.30265122e-02, 2.75392580e-04, 1.09603898e-04, 1.22103491e-04,\n",
              "        1.42945046e-05, 6.20420426e-02, 6.22462388e-03, 9.90633620e-04,\n",
              "        1.47475803e-04, 9.19462545e-05, 2.70816927e-05, 3.99781784e-05,\n",
              "        3.20082945e-05, 4.14015522e-05, 2.09322207e-05, 1.57801609e-04,\n",
              "        1.74211818e-04, 1.30081418e-04, 3.24410095e-04, 3.18331644e-04,\n",
              "        3.35837947e-04, 7.16313152e-05, 1.86091584e-05, 7.16459006e-03,\n",
              "        1.56736677e-03, 3.66014894e-04, 4.65131161e-05, 1.01356927e-05,\n",
              "        3.46494453e-05, 1.18772623e-05, 1.29340997e-05, 1.78118498e-05,\n",
              "        3.70101631e-02, 7.94386549e-04, 4.51747619e-04, 2.58633263e-05]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "pos = np.argmax(model.predict(padded_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJLGl4HSNjE0",
        "outputId": "9d3c91b4-2135-4d95-89cd-3bb89f9800f0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBUE1sHnNEO6",
        "outputId": "0de79777-1cf8-4547-fc7f-005ea199fb24"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': 1,\n",
              " 'a': 2,\n",
              " 'on': 3,\n",
              " 'to': 4,\n",
              " 'or': 5,\n",
              " 'for': 6,\n",
              " 'decisions': 7,\n",
              " 'of': 8,\n",
              " 'this': 9,\n",
              " 'life': 10,\n",
              " 'some': 11,\n",
              " 'be': 12,\n",
              " 'it': 13,\n",
              " 'buying': 14,\n",
              " 'after': 15,\n",
              " 'considering': 16,\n",
              " 'the': 17,\n",
              " 'and': 18,\n",
              " 'raw': 19,\n",
              " 'make': 20,\n",
              " 'plays': 21,\n",
              " 'vital': 22,\n",
              " 'role': 23,\n",
              " 'in': 24,\n",
              " 'our': 25,\n",
              " 'everyday': 26,\n",
              " 'directly': 27,\n",
              " 'indirectly': 28,\n",
              " 'daily': 29,\n",
              " 'we': 30,\n",
              " 'depend': 31,\n",
              " 'choosing': 32,\n",
              " 'novel': 33,\n",
              " 'read': 34,\n",
              " 'from': 35,\n",
              " 'list': 36,\n",
              " 'books': 37,\n",
              " 'thing': 38,\n",
              " 'budget': 39,\n",
              " 'so': 40,\n",
              " 'have': 41,\n",
              " 'you': 42,\n",
              " 'ever': 43,\n",
              " 'imagined': 44,\n",
              " 'searching': 45,\n",
              " 'something': 46,\n",
              " 'google': 47,\n",
              " 'yahoo': 48,\n",
              " 'generates': 49,\n",
              " 'lot': 50,\n",
              " 'is': 51,\n",
              " 'essential': 52,\n",
              " 'analyze': 53,\n",
              " 'user': 54,\n",
              " 'experiences': 55,\n",
              " 'getting': 56,\n",
              " 'recommendations': 57,\n",
              " 'various': 58,\n",
              " 'e': 59,\n",
              " 'commerce': 60,\n",
              " 'websites': 61,\n",
              " 'product': 62,\n",
              " 'tracking': 63,\n",
              " 'parcels': 64,\n",
              " 'during': 65,\n",
              " 'delivery': 66,\n",
              " 'are': 67,\n",
              " 'part': 68,\n",
              " 'analytics': 69,\n",
              " 'which': 70,\n",
              " 'involves': 71,\n",
              " 'analyzing': 72,\n",
              " 'informed': 73,\n",
              " 'but': 74,\n",
              " 'does': 75,\n",
              " 'not': 76,\n",
              " 'help': 77,\n",
              " 'if': 78,\n",
              " 'has': 79,\n",
              " 'redundancy': 80,\n",
              " 'inconsistency': 81,\n",
              " 'inaccuracy': 82,\n",
              " 'therefore': 83,\n",
              " 'needs': 84,\n",
              " 'cleaned': 85,\n",
              " 'before': 86,\n",
              " 'analysis': 87}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "  if index==pos:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emawpNAINzRC",
        "outputId": "de1c7873-e461-440a-e434-4d0c0e122cdb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plays\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"Data plays a vital role\"\n",
        "\n",
        "# tokenization\n",
        "token_text3 = tokenizer.texts_to_sequences([text3])[0]\n",
        "# padding\n",
        "padded_text3 = pad_sequences([token_text3], maxlen=33, padding='pre')\n",
        "# model prediction\n",
        "model.predict(padded_text3)\n",
        "\n",
        "pos3 = np.argmax(model.predict(padded_text3))\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index==pos3:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbbZiNtGOKjZ",
        "outputId": "9427820a-470f-4336-ea36-f8e3e4d260b6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"Data is a vital role in our everyday life\"\n",
        "\n",
        "# tokenization\n",
        "token_text3 = tokenizer.texts_to_sequences([text3])[0]\n",
        "# padding\n",
        "padded_text3 = pad_sequences([token_text3], maxlen=33, padding='pre')\n",
        "# model prediction\n",
        "model.predict(padded_text3)\n",
        "\n",
        "pos3 = np.argmax(model.predict(padded_text3))\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index==pos3:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYdZ-2gtOiHp",
        "outputId": "c942285f-baaf-4abc-da12-38e7e8d361f3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "life\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Improvements:**\n",
        "\n",
        "1. Increasing the LSTM units\n",
        "2. Increasing the Dense layers\n",
        "3. Increasing the data\n",
        "4. Using a pre-trained model on a larger corpus of data\n",
        "5. Hyper parameter optimization"
      ],
      "metadata": {
        "id": "m9yb7MU_PFyi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Savwt9c9O1Yx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}